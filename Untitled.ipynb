{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahsa26/xgboost_ts/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5308ac3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5308ac3e",
        "outputId": "f8623e22-484a-486f-8ccf-dc269979741d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numbers-parser\n",
            "  Downloading numbers-parser-2.3.9.tar.gz (223 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 223 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from numbers-parser) (3.17.3)\n",
            "Collecting python-snappy\n",
            "  Downloading python_snappy-0.6.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting roman\n",
            "  Downloading roman-3.3-py2.py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->numbers-parser) (1.15.0)\n",
            "Building wheels for collected packages: numbers-parser\n",
            "  Building wheel for numbers-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numbers-parser: filename=numbers_parser-2.3.9-py3-none-any.whl size=243068 sha256=2595b3fe0527df34d972e7a1924972c5984ac13acfb6cd5e4371512eeba744b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/17/2e/efaa4698ae3506b7be41fe10ca108cdbe546552ecdac11463a\n",
            "Successfully built numbers-parser\n",
            "Installing collected packages: roman, python-snappy, numbers-parser\n",
            "Successfully installed numbers-parser-2.3.9 python-snappy-0.6.1 roman-3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install numbers-parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45ac01b",
      "metadata": {
        "id": "d45ac01b"
      },
      "outputs": [],
      "source": [
        "from numbers_parser import Document\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0769d766",
      "metadata": {
        "id": "0769d766"
      },
      "outputs": [],
      "source": [
        "def convert2matrix(data_arr_on, data_arr_off , look_back, feature_idx0, feature_idx1):\n",
        "    X, Y =[], []\n",
        "    for i in range(len(data_arr_on)-look_back):\n",
        "        d=i+look_back  \n",
        "        X.append(np.concatenate((data_arr_off[i:d,feature_idx0],data_arr_off[i:d,feature_idx1])))\n",
        "        Y.append(data_arr_on[d])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "# np.concatenate(data_arr_on[i:d,feature_idx0],data_arr_on[i:d,feature_idx1])\n",
        "\n",
        "def model_dnn(optimizer='adam', activation_hl01='relu', activation_hl02='relu', num_node01=32, num_node02=8):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=num_node01, input_dim=look_back*num_features, activation=activation_hl01))\n",
        "    model.add(Dense(num_node02, activation=activation_hl02))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def model_loss(history):\n",
        "    plt.figure(figsize=(16,8))# 16 is x-axis length, 4 is y-axis length\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Test Loss')\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def cal_cc(testY, test_predict):\n",
        "    part01 = testY - np.mean(testY)\n",
        "    part02 = test_predict - np.mean(test_predict)\n",
        "    num = np.sum(part01 * part02)\n",
        "    den = np.sum(part01**2) * np.sum(part02**2)\n",
        "    if den == 0:\n",
        "        return 0\n",
        "    return num/np.sqrt(den)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb8f079",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffb8f079",
        "outputId": "5dad8b6d-3f36-4c39-c089-48142daae6a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "i-0 rows-287\n",
            "i-1 rows-720\n",
            "i-2 rows-744\n",
            "i-3 rows-481\n",
            "i-4 rows-287\n",
            "i-5 rows-720\n",
            "i-6 rows-744\n",
            "i-7 rows-481\n",
            "i-8 rows-287\n",
            "i-9 rows-720\n",
            "i-10 rows-744\n",
            "i-11 rows-481\n",
            "i-12 rows-287\n",
            "i-13 rows-720\n",
            "i-14 rows-744\n",
            "i-15 rows-481\n",
            "all_data (offshore)  (8928, 7)\n",
            "16\n",
            "i-0 rows-287\n",
            "i-1 rows-720\n",
            "i-2 rows-744\n",
            "i-3 rows-481\n",
            "i-4 rows-287\n",
            "i-5 rows-720\n",
            "i-6 rows-744\n",
            "i-7 rows-481\n",
            "i-8 rows-287\n",
            "i-9 rows-720\n",
            "i-10 rows-744\n",
            "i-11 rows-481\n",
            "i-12 rows-287\n",
            "i-13 rows-720\n",
            "i-14 rows-744\n",
            "i-15 rows-481\n",
            "all_data (nearshore)  (8928,)\n"
          ]
        }
      ],
      "source": [
        "# Read file\n",
        "doc = Document(\"offshore.numbers\")\n",
        "sheets = doc.sheets()\n",
        "#for i in range(len(sheets)):\n",
        "    #print(sheets[i].name)\n",
        "print(len(sheets))\n",
        "for i in range(len(sheets)):\n",
        "    tables = sheets[i].tables()#; print('tables', tables)\n",
        "    data_off = np.array(tables[0].rows(values_only=True))\n",
        "    if i%4 == 0:\n",
        "        columns = data_off[0]\n",
        "        data_off = data_off[458:,:]; print('i-{} rows-{}'.format(i, np.shape(data_off)[0]))\n",
        "        if i==0:\n",
        "            all_data_off = np.copy(data_off)\n",
        "        else:\n",
        "            all_data_off = np.concatenate((all_data_off, data_off))\n",
        "    elif i%4 == 3:\n",
        "        data_off = data_off[1:482,:]; print('i-{} rows-{}'.format(i, np.shape(data_off)[0]))\n",
        "        all_data_off = np.concatenate((all_data_off, data_off))\n",
        "    else:\n",
        "        data_off = data_off[1:,:]; print('i-{} rows-{}'.format(i, np.shape(data_off)[0]))\n",
        "        all_data_off = np.concatenate((all_data_off, data_off))\n",
        "\n",
        "print('all_data (offshore) ', np.shape(all_data_off))\n",
        "\n",
        "label_feature_idx = 2\n",
        "doc = Document(\"nearshore.numbers\")\n",
        "sheets = doc.sheets()\n",
        "#for i in range(len(sheets)):\n",
        "    #print(sheets[i].name)\n",
        "print(len(sheets))\n",
        "for i in range(len(sheets)):\n",
        "    tables = sheets[i].tables()#; print('tables', tables)\n",
        "    data_on = np.array(tables[0].rows(values_only=True))\n",
        "    if i%4 == 0:\n",
        "        data_on = data_on[458:,label_feature_idx]; print('i-{} rows-{}'.format(i, np.shape(data_on)[0]))\n",
        "        if i==0:\n",
        "            all_data_on = np.copy(data_on)\n",
        "        else:\n",
        "            all_data_on = np.concatenate((all_data_on, data_on))\n",
        "    elif i%4 == 3:\n",
        "        data_on = data_on[1:482,label_feature_idx]; print('i-{} rows-{}'.format(i, np.shape(data_on)[0]))\n",
        "        all_data_on = np.concatenate((all_data_on, data_on))\n",
        "    else:\n",
        "        data_on = data_on[1:,label_feature_idx]; print('i-{} rows-{}'.format(i, np.shape(data_on)[0]))\n",
        "        all_data_on = np.concatenate((all_data_on, data_on))\n",
        "\n",
        "print('all_data (nearshore) ', np.shape(all_data_on))\n",
        "\n",
        "\n",
        "#print(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f41cd39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f41cd39",
        "outputId": "b6767f41-013d-4e0a-a067-055a18c2e804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6249 8928\n",
            "(6249, 7) (2679, 7) (6249,) (2679,)\n"
          ]
        }
      ],
      "source": [
        "# approximately 70% data in training set and remaining in test set\n",
        "train_size = int(.7*np.shape(all_data_off)[0]); print(train_size, len(all_data_off))\n",
        "# training data without labels: 2-D\n",
        "train_off, test_off= all_data_off[0:train_size, :], all_data_off[train_size:len(all_data_off)+1, :]\n",
        "# label data: 1-D\n",
        "train_on, test_on = all_data_on[0:train_size], all_data_on[train_size:len(all_data_on)+1]\n",
        "\n",
        "print(train_off.shape, test_off.shape, train_on.shape, test_on.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a30113",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77a30113",
        "outputId": "dc36e60c-d52c-4aba-e100-3f6d986a4112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6247, 4) (6247,) (2677, 4) (2677,)\n",
            "[17:27:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:1.06252\n",
            "[1]\tvalidation_0-rmse:1.00666\n",
            "[2]\tvalidation_0-rmse:0.968365\n",
            "[3]\tvalidation_0-rmse:0.942126\n",
            "[4]\tvalidation_0-rmse:0.924517\n",
            "[5]\tvalidation_0-rmse:0.913838\n",
            "[6]\tvalidation_0-rmse:0.910923\n",
            "[7]\tvalidation_0-rmse:0.911145\n",
            "[8]\tvalidation_0-rmse:0.914808\n",
            "[9]\tvalidation_0-rmse:0.919059\n",
            "Mean Squared Error: 0.84466857\n",
            "Root Mean Squared Error: 0.9190585\n",
            "Pearson Correlation Coefficient (test) 0.05742481\n"
          ]
        }
      ],
      "source": [
        "# Prepare time series dataset\n",
        "num_features=2\n",
        "look_back = 2\n",
        "#0:Day, 1:hour, 2:Hs, 3:spr, 4:dir, 5:Tm, 6:Tp\n",
        "feature_idx0 = 2\n",
        "feature_idx1 = 3\n",
        "trainX, trainY = convert2matrix(train_on, train_off, look_back, feature_idx0, feature_idx1)\n",
        "testX, testY = convert2matrix(test_on, train_off, look_back, feature_idx0, feature_idx1)\n",
        "print(np.shape(trainX), np.shape(trainY), np.shape(testX), np.shape(testY))\n",
        "\n",
        "trainX = np.asarray(trainX).astype(np.float32)\n",
        "testX = np.asarray(testX).astype(np.float32)\n",
        "trainY = np.asarray(trainY).astype(np.float32)\n",
        "testY = np.asarray(testY).astype(np.float32)\n",
        "\n",
        "xgb = XGBRegressor(n_estimators = 10)#tree_method=\"hist\"\n",
        "xgb.fit(trainX, trainY, eval_set=[(testX, testY)])\n",
        "y_pred = xgb.predict(testX)\n",
        "\n",
        "#print('Mean Absolute Error:', metrics.mean_absolute_error(testY, y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(testY, y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(testY, y_pred)))\n",
        "print(\"Pearson Correlation Coefficient (test)\", cal_cc(testY, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Expeiment complete')\n",
        "print('testing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY-JEcWT3SE9",
        "outputId": "11da52a0-5957-452e-d266-2150ec3bf45d"
      },
      "id": "kY-JEcWT3SE9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expeiment complete\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}